# ğŸ§  CIFAR-10 Classification: AlexNet vs MobileNet-like CNNs

This project compares two deep learning models â€” **AlexNet** and a custom **MobileNet-like architecture** â€” built from scratch to classify images in the CIFAR-10 dataset using Convolutional Neural Networks (CNNs).

---

## ğŸ“Œ Table of Contents

- [ğŸ“– About the Project](#-about-the-project)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸ” What is a CNN?](#-what-is-a-cnn)
- [ğŸ—ï¸ Architectures Used](#-architectures-used)
  - [AlexNet](#alexnet)
  - [MobileNet-like](#mobilenet-like)
- [âš™ï¸ Training Details](#-training-details)
- [ğŸ“ˆ Results](#-results)
- [ğŸ§ª Sample Predictions](#-sample-predictions)
- [ğŸ“‚ Repository Structure](#-repository-structure)
- [ğŸš€ How to Run](#-how-to-run)
- [ğŸ“ License](#-license)

---

## ğŸ“– About the Project

This project aims to implement and compare **two CNN models** on the CIFAR-10 dataset:
- **AlexNet** (simplified for 32Ã—32 input)
- **MobileNet-like CNN** (depthwise separable convolution-based)

We evaluate both models on:
- Accuracy
- Precision, Recall, F1-Score
- Inference Time

---

## ğŸ“Š Dataset

**CIFAR-10** is a labeled subset of the 80 million tiny images dataset.  
- 60,000 images of 32x32 resolution in 10 classes.
- 50,000 images for training, 10,000 for testing.
- Classes: `airplane`, `automobile`, `bird`, `cat`, `deer`, `dog`, `frog`, `horse`, `ship`, `truck`.

---

## ğŸ” What is a CNN?

A **Convolutional Neural Network (CNN)** is a deep learning model especially effective for image-related tasks.  
It consists of layers that automatically detect patterns such as edges, textures, and object parts from pixel data.

---

## ğŸ—ï¸ Architectures Used

### ğŸŸ¦ AlexNet
- Based on the original AlexNet (2012) but scaled down for 32x32 inputs.
- **Architecture Summary**:
  - Multiple Conv + BatchNorm + ReLU layers
  - MaxPooling for downsampling
  - Fully Connected Layers (1024 â†’ 512 â†’ 10)
  - Dropout for regularization
Input â†’ Conv2D â†’ MaxPool â†’ Conv2D â†’ MaxPool â†’ Conv2D â†’ Conv2D â†’ MaxPool â†’ FC â†’ Dropout â†’ FC â†’ Dropout â†’ Output

---

### ğŸŸ© MobileNet-like
- Inspired by **MobileNet v1**, optimized for speed.
- Uses **Depthwise Separable Convolutions** for fewer parameters and faster inference.
- Ends with **GlobalAveragePooling** before classification.
Input â†’ Conv2D â†’ [Depthwise + Pointwise] â†’ MaxPool â†’ [Depthwise + Pointwise] â†’ GAP â†’ Output

---

## âš™ï¸ Training Details

- **Epochs**: 50  
- **Optimizer**: Adam  
- **Loss Function**: Categorical Crossentropy  
- **Batch Size**: 128  
- **Early Stopping**: Yes (patience=5)

---

## ğŸš€ How to Run

1. Open [`AlexNet_vs_MobileNet.ipynb`](./AlexNet_vs_MobileNet.ipynb) in [Google Colab](https://colab.research.google.com/).
2. Run all cells sequentially.
3. Observe training, metrics, plots, and sample predictions.



